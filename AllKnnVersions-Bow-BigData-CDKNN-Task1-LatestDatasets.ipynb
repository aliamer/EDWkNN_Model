{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Latest Datasets\\\\banknote'\n",
      "###############\n",
      "{0: 0, 1: 1}\n",
      "metric Euclidean\n",
      "measure Accuracy\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "+----------+----------+------------+-----------------------+-----------------------+\n",
      "|    k     | Accuracy | Train Time |       Test time       |       Total Time      |\n",
      "+----------+----------+------------+-----------------------+-----------------------+\n",
      "|    5     |  0.9565  |  0:00:00   |     0:00:00.011267    |     0:00:00.011267    |\n",
      "|    15    |  0.942   |  0:00:00   |     0:00:00.012258    |     0:00:00.012258    |\n",
      "|    30    |  0.9275  |  0:00:00   |     0:00:00.013674    |     0:00:00.013674    |\n",
      "|    45    |  0.9203  |  0:00:00   |     0:00:00.017484    |     0:00:00.017484    |\n",
      "| Average  |  0.9366  |  0:00:00   |     0:00:00.013671    |     0:00:00.013671    |\n",
      "| Std Dev. |  0.0139  |    0.0     | 0.0023618141475825766 | 0.0023618141475825766 |\n",
      "+----------+----------+------------+-----------------------+-----------------------+\n",
      "metric Euclidean\n",
      "measure Precision\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "+----------+-----------+------------+-----------------------+-----------------------+\n",
      "|    k     | Precision | Train Time |       Test time       |       Total Time      |\n",
      "+----------+-----------+------------+-----------------------+-----------------------+\n",
      "|    5     |   0.9549  |  0:00:00   |     0:00:00.011267    |     0:00:00.011267    |\n",
      "|    15    |   0.9401  |  0:00:00   |     0:00:00.012258    |     0:00:00.012258    |\n",
      "|    30    |   0.9275  |  0:00:00   |     0:00:00.013674    |     0:00:00.013674    |\n",
      "|    45    |   0.9195  |  0:00:00   |     0:00:00.017484    |     0:00:00.017484    |\n",
      "| Average  |   0.9355  |  0:00:00   |     0:00:00.013671    |     0:00:00.013671    |\n",
      "| Std Dev. |   0.0134  |    0.0     | 0.0023618141475825766 | 0.0023618141475825766 |\n",
      "+----------+-----------+------------+-----------------------+-----------------------+\n",
      "metric Euclidean\n",
      "measure micro Precision\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "+----------+-----------------+------------+-----------------------+-----------------------+\n",
      "|    k     | micro Precision | Train Time |       Test time       |       Total Time      |\n",
      "+----------+-----------------+------------+-----------------------+-----------------------+\n",
      "|    5     |      0.9565     |  0:00:00   |     0:00:00.011267    |     0:00:00.011267    |\n",
      "|    15    |      0.942      |  0:00:00   |     0:00:00.012258    |     0:00:00.012258    |\n",
      "|    30    |      0.9275     |  0:00:00   |     0:00:00.013674    |     0:00:00.013674    |\n",
      "|    45    |      0.9203     |  0:00:00   |     0:00:00.017484    |     0:00:00.017484    |\n",
      "| Average  |      0.9366     |  0:00:00   |     0:00:00.013671    |     0:00:00.013671    |\n",
      "| Std Dev. |      0.0139     |    0.0     | 0.0023618141475825766 | 0.0023618141475825766 |\n",
      "+----------+-----------------+------------+-----------------------+-----------------------+\n",
      "metric Euclidean\n",
      "measure Recall\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "+----------+--------+------------+-----------------------+-----------------------+\n",
      "|    k     | Recall | Train Time |       Test time       |       Total Time      |\n",
      "+----------+--------+------------+-----------------------+-----------------------+\n",
      "|    5     | 0.9576 |  0:00:00   |     0:00:00.011267    |     0:00:00.011267    |\n",
      "|    15    | 0.9446 |  0:00:00   |     0:00:00.012258    |     0:00:00.012258    |\n",
      "|    30    | 0.9334 |  0:00:00   |     0:00:00.013674    |     0:00:00.013674    |\n",
      "|    45    | 0.9252 |  0:00:00   |     0:00:00.017484    |     0:00:00.017484    |\n",
      "| Average  | 0.9402 |  0:00:00   |     0:00:00.013671    |     0:00:00.013671    |\n",
      "| Std Dev. | 0.0122 |    0.0     | 0.0023618141475825766 | 0.0023618141475825766 |\n",
      "+----------+--------+------------+-----------------------+-----------------------+\n",
      "metric Euclidean\n",
      "measure micro Recall\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "+----------+--------------+------------+-----------------------+-----------------------+\n",
      "|    k     | micro Recall | Train Time |       Test time       |       Total Time      |\n",
      "+----------+--------------+------------+-----------------------+-----------------------+\n",
      "|    5     |    0.9565    |  0:00:00   |     0:00:00.011267    |     0:00:00.011267    |\n",
      "|    15    |    0.942     |  0:00:00   |     0:00:00.012258    |     0:00:00.012258    |\n",
      "|    30    |    0.9275    |  0:00:00   |     0:00:00.013674    |     0:00:00.013674    |\n",
      "|    45    |    0.9203    |  0:00:00   |     0:00:00.017484    |     0:00:00.017484    |\n",
      "| Average  |    0.9366    |  0:00:00   |     0:00:00.013671    |     0:00:00.013671    |\n",
      "| Std Dev. |    0.0139    |    0.0     | 0.0023618141475825766 | 0.0023618141475825766 |\n",
      "+----------+--------------+------------+-----------------------+-----------------------+\n",
      "metric Euclidean\n",
      "measure F Measure\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "+----------+-----------+------------+-----------------------+-----------------------+\n",
      "|    k     | F Measure | Train Time |       Test time       |       Total Time      |\n",
      "+----------+-----------+------------+-----------------------+-----------------------+\n",
      "|    5     |   0.9561  |  0:00:00   |     0:00:00.011267    |     0:00:00.011267    |\n",
      "|    15    |   0.9416  |  0:00:00   |     0:00:00.012258    |     0:00:00.012258    |\n",
      "|    30    |   0.9273  |  0:00:00   |     0:00:00.013674    |     0:00:00.013674    |\n",
      "|    45    |   0.9199  |  0:00:00   |     0:00:00.017484    |     0:00:00.017484    |\n",
      "| Average  |   0.9362  |  0:00:00   |     0:00:00.013671    |     0:00:00.013671    |\n",
      "| Std Dev. |   0.0138  |    0.0     | 0.0023618141475825766 | 0.0023618141475825766 |\n",
      "+----------+-----------+------------+-----------------------+-----------------------+\n",
      "metric Euclidean\n",
      "measure micro F Measure\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "+----------+-----------------+------------+-----------------------+-----------------------+\n",
      "|    k     | micro F Measure | Train Time |       Test time       |       Total Time      |\n",
      "+----------+-----------------+------------+-----------------------+-----------------------+\n",
      "|    5     |      0.9565     |  0:00:00   |     0:00:00.011267    |     0:00:00.011267    |\n",
      "|    15    |      0.942      |  0:00:00   |     0:00:00.012258    |     0:00:00.012258    |\n",
      "|    30    |      0.9275     |  0:00:00   |     0:00:00.013674    |     0:00:00.013674    |\n",
      "|    45    |      0.9203     |  0:00:00   |     0:00:00.017484    |     0:00:00.017484    |\n",
      "| Average  |      0.9366     |  0:00:00   |     0:00:00.013671    |     0:00:00.013671    |\n",
      "| Std Dev. |      0.0139     |    0.0     | 0.0023618141475825766 | 0.0023618141475825766 |\n",
      "+----------+-----------------+------------+-----------------------+-----------------------+\n",
      "metric Euclidean\n",
      "measure ROC\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "+----------+--------+------------+-----------------------+-----------------------+\n",
      "|    k     |  ROC   | Train Time |       Test time       |       Total Time      |\n",
      "+----------+--------+------------+-----------------------+-----------------------+\n",
      "|    5     | 0.9576 |  0:00:00   |     0:00:00.011267    |     0:00:00.011267    |\n",
      "|    15    | 0.9446 |  0:00:00   |     0:00:00.012258    |     0:00:00.012258    |\n",
      "|    30    | 0.9334 |  0:00:00   |     0:00:00.013674    |     0:00:00.013674    |\n",
      "|    45    | 0.9252 |  0:00:00   |     0:00:00.017484    |     0:00:00.017484    |\n",
      "| Average  | 0.9402 |  0:00:00   |     0:00:00.013671    |     0:00:00.013671    |\n",
      "| Std Dev. | 0.0122 |    0.0     | 0.0023618141475825766 | 0.0023618141475825766 |\n",
      "+----------+--------+------------+-----------------------+-----------------------+\n",
      "metric Euclidean\n",
      "measure Average Mean Precison\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "+----------+-----------------------+------------+-----------------------+-----------------------+\n",
      "|    k     | Average Mean Precison | Train Time |       Test time       |       Total Time      |\n",
      "+----------+-----------------------+------------+-----------------------+-----------------------+\n",
      "|    5     |         0.9203        |  0:00:00   |     0:00:00.011267    |     0:00:00.011267    |\n",
      "|    15    |         0.8924        |  0:00:00   |     0:00:00.012258    |     0:00:00.012258    |\n",
      "|    30    |         0.8626        |  0:00:00   |     0:00:00.013674    |     0:00:00.013674    |\n",
      "|    45    |         0.8537        |  0:00:00   |     0:00:00.017484    |     0:00:00.017484    |\n",
      "| Average  |         0.8822        |  0:00:00   |     0:00:00.013671    |     0:00:00.013671    |\n",
      "| Std Dev. |         0.0262        |    0.0     | 0.0023618141475825766 | 0.0023618141475825766 |\n",
      "+----------+-----------------------+------------+-----------------------+-----------------------+\n",
      "metric Euclidean\n",
      "measure MAE\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "+----------+--------+------------+-----------------------+-----------------------+\n",
      "|    k     |  MAE   | Train Time |       Test time       |       Total Time      |\n",
      "+----------+--------+------------+-----------------------+-----------------------+\n",
      "|    5     | 0.0435 |  0:00:00   |     0:00:00.011267    |     0:00:00.011267    |\n",
      "|    15    | 0.058  |  0:00:00   |     0:00:00.012258    |     0:00:00.012258    |\n",
      "|    30    | 0.0725 |  0:00:00   |     0:00:00.013674    |     0:00:00.013674    |\n",
      "|    45    | 0.0797 |  0:00:00   |     0:00:00.017484    |     0:00:00.017484    |\n",
      "| Average  | 0.0634 |  0:00:00   |     0:00:00.013671    |     0:00:00.013671    |\n",
      "| Std Dev. | 0.0139 |    0.0     | 0.0023618141475825766 | 0.0023618141475825766 |\n",
      "+----------+--------+------------+-----------------------+-----------------------+\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'kappa_avg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 366\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m###############\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    365\u001b[0m     Weights\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mones(train_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 366\u001b[0m     \u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtermOccurance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtermOcc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdocOccurance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocOcc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    367\u001b[0m list1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m30\u001b[39m,\u001b[38;5;241m45\u001b[39m]\n\u001b[0;32m    368\u001b[0m tables\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m************* Average Results ***********\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mencode())\n",
      "Cell \u001b[1;32mIn[1], line 302\u001b[0m, in \u001b[0;36mclassify\u001b[1;34m(k, metric, termOccurance, docOccurance)\u001b[0m\n\u001b[0;32m    300\u001b[0m AMP_avg\u001b[38;5;241m.\u001b[39mextend(averageMeanPrecison)\n\u001b[0;32m    301\u001b[0m mae_avg\u001b[38;5;241m.\u001b[39mextend(mae)\n\u001b[1;32m--> 302\u001b[0m \u001b[43mkappa_avg\u001b[49m\u001b[38;5;241m.\u001b[39mextend(kappa)\n\u001b[0;32m    303\u001b[0m avg_test_time\u001b[38;5;241m.\u001b[39mextend(test_time)\n\u001b[0;32m    304\u001b[0m avg_train_time\u001b[38;5;241m.\u001b[39mextend(train_time)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kappa_avg' is not defined"
     ]
    }
   ],
   "source": [
    "# importing all the required modules\n",
    "\n",
    "from importlib import reload\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from prettytable import PrettyTable\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import recall_score,precision_score,average_precision_score,f1_score\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,mean_absolute_error,cohen_kappa_score\n",
    "from sklearn.preprocessing import label_binarize,LabelEncoder\n",
    "import statistics\n",
    "import math\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "import csv\n",
    "from collections import Counter\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "import statistics\n",
    "from scipy.stats import pearsonr,entropy,mode\n",
    "from scipy.io import arff\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import warnings,os,scipy\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "\n",
    "\n",
    "def loadNonIRDatasets(dataset):\n",
    "    documents,labels=[],[]\n",
    "    fname=dataset+'.csv'\n",
    "    with open(fname, 'r') as file:\n",
    "        reader = csv.reader(file, delimiter = ',')\n",
    "        for row in reader:\n",
    "            if len(row)>0:\n",
    "                if '?' in row:\n",
    "                    continue\n",
    "                doc=row[0:len(row)-2]\n",
    "                try:\n",
    "                    doc=[abs(float(d)) for d in doc]\n",
    "                except:\n",
    "                    continue\n",
    "                documents.append(doc)\n",
    "                #print(row)\n",
    "                labels.append(row[len(row)-1])\n",
    "\n",
    "    return documents,labels\n",
    "\n",
    "def Cosine(a, b):#distance\n",
    "    return distance.cosine(a,b)\n",
    "\n",
    "def Euclidean(a, b):#distance\n",
    "    return distance.euclidean(a,b)\n",
    "\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "def PrintDetails(metric=\"smtp\",measure= \"Accuracy\",Arr=None,kList=[5,15,30,45],train_time=0,test_time=0,std=[]):\n",
    "    x = PrettyTable()\n",
    "    #kList=[1,3,5,9,15,30,45]#,70,90,120]\n",
    "    #if std==[]:\n",
    "    if len(std)==0:\n",
    "        x.field_names = [\"k\",measure,\"Train Time\",\"Test time\",\"Total Time\"]\n",
    "    else:\n",
    "        x.field_names = [\"Split\",measure,\"std\",\"Train Time\",\"Test time\",\"Total Time\"]\n",
    "        \n",
    "    print(\"metric\",metric)\n",
    "    print(\"measure\",measure)\n",
    "    tables.write((\"metric\\t\"+str(metric)+\"\\n\").encode())\n",
    "    tables.write((\"measure\\t\"+str(measure)+\"\\n\").encode())\n",
    "    average=0\n",
    "    total_time=np.add(train_time,test_time)\n",
    "    for i in range(0,len(Arr)):\n",
    "        print(train_time[i])\n",
    "        tr_time=str(timedelta(seconds=(train_time[i])))\n",
    "        ts_time=str(timedelta(seconds=(test_time[i])))\n",
    "        \n",
    "        tot_time=str(timedelta(seconds=(total_time[i])))\n",
    "        if len(std)==0:\n",
    "            x.add_row([str(kList[i]),round(Arr[i],4),tr_time,ts_time,tot_time]) \n",
    "        else:\n",
    "            x.add_row([str(kList[i]),round(Arr[i],4),round(std[i],4),tr_time,ts_time,tot_time]) \n",
    "            \n",
    "        average+=Arr[i]\n",
    "    if len(std)==0:\n",
    "        x.add_row([\"Average\",round((average/len(Arr)),4),str(timedelta(seconds=np.mean(train_time))),\n",
    "                   str(timedelta(seconds=np.mean(test_time))),str(timedelta(seconds=np.mean(total_time)))]) \n",
    "        x.add_row([\"Std Dev.\",round(np.std(Arr),4),np.std(train_time),\n",
    "                   np.std(test_time),np.std(total_time)])   \n",
    "    else:\n",
    "        x.add_row([\"Average\",round((average/len(Arr)),4),round(np.mean(std),4),str(timedelta(seconds=np.mean(train_time))),\n",
    "                   str(timedelta(seconds=np.mean(test_time))),str(timedelta(seconds=np.mean(total_time)))]) \n",
    "        x.add_row([\"Std Dev.\",round(np.std(Arr),4),round(np.std(std),4),\n",
    "                   round(np.std(train_time),10),\n",
    "                   round(np.std(test_time),10),\n",
    "                   round(np.std(total_time),10)])\n",
    "        \n",
    "    x.padding_width =1\n",
    "    tables.write(str(x).encode())\n",
    "    print(x)\n",
    "\n",
    "class CDNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self,n_neighbors=20,distance_metric='euclidean'):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.distance_metric=distance_metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the k-nearest neighbors classifier from the training dataset.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "          Training data.\n",
    "        y : {array-like, sparse matrix} of shape (n_samples,)\n",
    "          Target values.\n",
    "        Returns\n",
    "        -------\n",
    "        self : KCDNNClassifier\n",
    "          The fitted k- Centroid Displacement based nearest neighbors classifier.\n",
    "        \"\"\"\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "\n",
    "        self.fitted_ = True\n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.fitted_ == None:\n",
    "            raise Exception('predict() called before fit()')\n",
    "        else:\n",
    "            input_dim=X.shape[1]\n",
    "            #calculate distance\n",
    "            d=scipy.spatial.distance.cdist(X,self.X_,self.distance_metric)\n",
    "            #get k lowest distance and save to Sx\n",
    "            indexes=np.argsort(d)[:,:self.n_neighbors] # return k indexes of lowest value in d\n",
    "\n",
    "            y_pred=[] ##set y_predict list\n",
    "            for n,index in enumerate(indexes): ##looping through k indexes over the whole test dataset\n",
    "                Sx = dict()\n",
    "                for idx in range(self.n_neighbors):\n",
    "                    key = index[idx]\n",
    "                    if self.y_[key] in Sx:\n",
    "                        Sx[self.y_[key]].append(self.X_[key])\n",
    "                    else:\n",
    "                        Sx[self.y_[key]] = []\n",
    "                        Sx[self.y_[key]].append(self.X_[key])\n",
    "\n",
    "                #calculate current centroids within training dataset\n",
    "                px = dict()\n",
    "                for key in Sx:\n",
    "                    sum_item = np.zeros(input_dim)\n",
    "                    for i in range(len(Sx[key])):\n",
    "                        sum_item += Sx[key][i]\n",
    "                    px_item = sum_item/len(Sx[key])\n",
    "                    px[key] = px_item\n",
    "\n",
    "                #calculate new centroid by adding new test data\n",
    "                qx = dict()\n",
    "                for key in Sx:\n",
    "                    sum_item = np.zeros(input_dim)\n",
    "                    for i in range(len(Sx[key])):\n",
    "                        sum_item+=Sx[key][i]\n",
    "                    sum_item += X[n]\n",
    "                    qx_item = sum_item/(len(Sx[key]) + 1)\n",
    "                    qx[key] = qx_item\n",
    "\n",
    "                #calculate displacement\n",
    "                theta = dict()\n",
    "                for key in px:\n",
    "                    if key in qx:\n",
    "                        theta[key] = np.linalg.norm(px[key] - qx[key])\n",
    "\n",
    "                label=min(theta, key=theta.get)\n",
    "                y_pred.append(label)\n",
    "        return np.array(y_pred)\n",
    "def classify(k=3,metric=\"euclidean\",termOccurance=None, docOccurance=None):\n",
    "    accuracy=[]\n",
    "    precision=[]\n",
    "    Recall=[]\n",
    "    fMeasure=[]\n",
    "    mprecision=[]\n",
    "    mRecall=[]\n",
    "    mfMeasure=[]\n",
    "    roc=[]\n",
    "    y_pred=[]\n",
    "    mae=[]\n",
    "    kappa=[]\n",
    "    averageMeanPrecison=[]\n",
    "    func=globals()[metric]\n",
    "    kList=[5,15,30,45]\n",
    "    theta=1\n",
    "    var=np.zeros(train_data.shape[1])\n",
    "    train_time=[]\n",
    "    test_time=[]\n",
    "    M=5\n",
    "    alpha=0.5\n",
    "    for k in kList:\n",
    "        time1=time.time()\n",
    "        knn=CDNNClassifier(n_neighbors=k).fit(train_data,train_labels)\n",
    "        time2=time.time()\n",
    "        pred=knn.predict(test_data)    \n",
    "        y_pred.append(pred)\n",
    "        time3=time.time()\n",
    "        train_time.append(time2-time1)\n",
    "        test_time.append(time3-time2)\n",
    " \n",
    "   \n",
    "    class_dict={}\n",
    "    classes=list(set(labels))\n",
    "    for i in range(0,len(classes)):\n",
    "        class_dict[classes[i]]=i\n",
    "    print(class_dict)\n",
    "    num_testLabels=[]\n",
    "    for i in range(0,len(test_labels)):\n",
    "        num_testLabels.append(class_dict[test_labels[i]])\n",
    "       \n",
    "    for i in range(0,len(y_pred)):\n",
    "        test_labels1=list(test_labels)\n",
    "        #Accuracy\n",
    "       \n",
    "        accuracy.append(accuracy_score(test_labels, y_pred[i]))\n",
    "        \n",
    "        #Precison\n",
    "        precision.append(precision_score(test_labels, y_pred[i],average='macro'))\n",
    "         \n",
    "        #Recall\n",
    "        Recall.append(recall_score(test_labels, y_pred[i],average='macro'))\n",
    "           \n",
    "        #f measure\n",
    "        fMeasure.append(f1_score(test_labels, y_pred[i],average='macro'))\n",
    "        \n",
    "        #Precison\n",
    "        mprecision.append(precision_score(test_labels, y_pred[i],average='micro'))\n",
    "         \n",
    "        #Recall\n",
    "        mRecall.append(recall_score(test_labels, y_pred[i],average='micro'))\n",
    "           \n",
    "        #f measure\n",
    "        mfMeasure.append(f1_score(test_labels, y_pred[i],average='micro'))\n",
    "        \n",
    "        kappa.append(cohen_kappa_score(test_labels, y_pred[i]))\n",
    "      \n",
    "        test = label_binarize(test_labels1, classes=categories).reshape((-1))\n",
    "        pred = label_binarize( y_pred[i], classes=categories).reshape((-1))\n",
    "        \n",
    "        #roc\n",
    "        try:\n",
    "            roc.append(roc_auc_score(test,pred))\n",
    "        except:\n",
    "            roc.append(-1)\n",
    "            \n",
    "        #Average Mean Precision\n",
    "        #y_val_true, val_pred = y_val_true.reshape((-1)), val_pred.reshape((-1))\n",
    "        averageMeanPrecison.append(average_precision_score(test, pred))\n",
    "        #MAE\n",
    "        num_pred=[]\n",
    "        for j in range(0,len(y_pred[i])):\n",
    "            num_pred.append(class_dict[y_pred[i][j]])\n",
    "        mae.append(mean_absolute_error(num_testLabels, num_pred))\n",
    "        \n",
    "        #PrintDetails(metric=metric,time=str(timedelta(seconds=(time2-time1))),measure=\"Average Mean Precison\",Arr=averageMeanPrecison)\n",
    "\n",
    "\n",
    "    \n",
    "   #Accuracy\n",
    "    PrintDetails(metric=metric,measure=\"Accuracy\",Arr=accuracy,train_time=train_time,test_time=test_time)\n",
    "    \n",
    "    #Precison\n",
    "    PrintDetails(metric=metric,measure=\"Precision\",Arr=precision,train_time=train_time,test_time=test_time)\n",
    "    #Precison\n",
    "    PrintDetails(metric=metric,measure=\"micro Precision\",Arr=mprecision,train_time=train_time,test_time=test_time)\n",
    "    #Recall\n",
    "    PrintDetails(metric=metric,measure=\"Recall\",Arr=Recall,train_time=train_time,test_time=test_time)\n",
    "     #Recall\n",
    "    PrintDetails(metric=metric,measure=\"micro Recall\",Arr=mRecall,train_time=train_time,test_time=test_time)\n",
    "    #f measure\n",
    "    PrintDetails(metric=metric,measure=\"F Measure\",Arr=fMeasure,train_time=train_time,test_time=test_time)\n",
    "    \n",
    "    #f measure\n",
    "    PrintDetails(metric=metric,measure=\"micro F Measure\",Arr=mfMeasure,train_time=train_time,test_time=test_time)\n",
    "    \n",
    "    #roc\n",
    "    PrintDetails(metric=metric,measure=\"ROC\",Arr=roc,train_time=train_time,test_time=test_time)\n",
    "    #Average Mean Precision\n",
    "    PrintDetails(metric=metric,measure=\"Average Mean Precison\",Arr=averageMeanPrecison,train_time=train_time,test_time=test_time)\n",
    "    #MAE\n",
    "    PrintDetails(metric=metric,measure=\"MAE\",Arr=mae,train_time=train_time,test_time=test_time)\n",
    "  \n",
    "    accuracy_avg.append(accuracy)\n",
    "    precision_avg.append(precision)\n",
    "    recall_avg.append(Recall)\n",
    "    macroFMeasure_avg.append(fMeasure)\n",
    "    mprecision_avg.append(mprecision)\n",
    "    mrecall_avg.append(mRecall)\n",
    "    mFMeasure_avg.append(mfMeasure)\n",
    "    roc_avg.append(roc)\n",
    "    AMP_avg.append(averageMeanPrecison)\n",
    "    mae_avg.append(mae)\n",
    "    avg_test_time.append(test_time)\n",
    "    avg_train_time.append(train_time)\n",
    "    \n",
    "import glob\n",
    "datasets=[]\n",
    "for file_name in glob.glob(\"Latest Datasets\\\\\"+'*.csv'):\n",
    "    file=os.path.split(file_name)[1]\n",
    "    datasets.append(os.path.splitext(file)[0])\n",
    "\n",
    "    \n",
    "for dataset in datasets:\n",
    "    fname=\"Latest Datasets\\\\\"+dataset\n",
    "    print(fname.encode())\n",
    "    arr,labels=loadNonIRDatasets(fname)\n",
    "    arr=np.array(arr)\n",
    "    labels=np.array(labels)\n",
    "    labels=list(labels)\n",
    "    le = LabelEncoder()\n",
    "    labels=le.fit_transform(labels)\n",
    "    categories=list(set(labels))\n",
    "    measures=[\"Euclidean\"]\n",
    "    global w\n",
    "    w=0\n",
    "    global Weights\n",
    "    for met in measures:\n",
    "        n_split=1\n",
    "        labels=np.array(labels)\n",
    "        path = \"CDKNN\\\\April Task1\\\\Latest Datasets\"\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        fname=path+'\\\\table_'+dataset+'_'+met+'_CDKNN.txt'\n",
    "        tables = open(fname, 'wb')\n",
    "        k_splits=10\n",
    "        accuracy_avg=[]\n",
    "        precision_avg=[]\n",
    "        recall_avg=[]\n",
    "        macroFMeasure_avg=[]\n",
    "        mprecision_avg=[]\n",
    "        mrecall_avg=[]\n",
    "        mFMeasure_avg=[]\n",
    "        roc_avg=[]\n",
    "        AMP_avg=[]\n",
    "        mae_avg=[]\n",
    "        avg_test_time=[]\n",
    "        avg_train_time=[]\n",
    "        kf = StratifiedKFold(n_splits=k_splits)\n",
    "        for trn_ind, tst_ind in kf.split(arr,labels):\n",
    "            xTrain, xTest = arr[trn_ind], arr[tst_ind]\n",
    "            yTrain, yTest = labels[trn_ind], labels[tst_ind]\n",
    "            train_data=np.array(xTrain)\n",
    "            test_data=np.array(xTest)\n",
    "            train_labels=np.array(yTrain)\n",
    "            test_labels=np.array(yTest)\n",
    "            allData=arr\n",
    "            termOcc=[]\n",
    "            docOcc=[]\n",
    "            tables.write(\"\\n*************\".encode())\n",
    "            tables.write((\" Split\\t\"+str(n_split)).encode())\n",
    "            tables.write(\" ***********\\n\".encode())\n",
    "            n_split=n_split+1\n",
    "            k=1\n",
    "            print(\"###############\")\n",
    "            Weights=np.ones(train_data.shape[0])\n",
    "            classify(k=k,metric=met,termOccurance=termOcc,docOccurance=docOcc)\n",
    "        list1=[5,15,30,45]\n",
    "        tables.write(\"\\n************* Average Results ***********\\n\".encode())\n",
    "        acc_std=np.std(np.array(accuracy_avg),axis=0)\n",
    "        accuracy_avg=np.mean(np.array(accuracy_avg),axis=0)\n",
    "        \n",
    "        pr_std=np.std(np.array(precision_avg),axis=0)\n",
    "        precision_avg=np.mean(np.array(precision_avg),axis=0)\n",
    "        \n",
    "        mpr_std=np.std(np.array(mprecision_avg),axis=0)\n",
    "        mprecision_avg=np.mean(np.array(mprecision_avg),axis=0)\n",
    "        \n",
    "        rcl_std=np.std(np.array(recall_avg),axis=0)\n",
    "        recall_avg=np.mean(np.array(recall_avg),axis=0)\n",
    "        \n",
    "        mrcl_std=np.std(np.array(mrecall_avg),axis=0)\n",
    "        mrecall_avg=np.mean(np.array(mrecall_avg),axis=0)\n",
    "        \n",
    "        F_std=np.std(np.array(macroFMeasure_avg),axis=0)\n",
    "        macroFMeasure_avg=np.mean(np.array(macroFMeasure_avg),axis=0)\n",
    "        \n",
    "        mF_std=np.std(np.array(mFMeasure_avg),axis=0)\n",
    "        mFMeasure_avg=np.mean(np.array(mFMeasure_avg),axis=0)\n",
    "        \n",
    "        roc_std=np.std(np.array(roc_avg),axis=0)\n",
    "        roc_avg=np.mean(np.array(roc_avg),axis=0)\n",
    "        \n",
    "        amp_std=np.std(np.array(AMP_avg),axis=0)\n",
    "        AMP_avg=np.mean(np.array(AMP_avg),axis=0)\n",
    "        \n",
    "        mae_std=np.std(np.array(mae_avg),axis=0)\n",
    "        mae_avg=np.mean(np.array(mae_avg),axis=0)\n",
    "        \n",
    "        avg_train_time=np.mean(np.array(avg_train_time),axis=0)\n",
    "        avg_test_time=np.mean(np.array(avg_test_time),axis=0)\n",
    "        #Accuracy\n",
    "        PrintDetails(metric=met,measure=\"Accuracy\",Arr=accuracy_avg,kList=list1,train_time=avg_train_time,test_time=avg_test_time,std=acc_std)\n",
    "        \n",
    "        #Precision\n",
    "        PrintDetails(metric=met,measure=\"Precision\",Arr=precision_avg,kList=list1,train_time=avg_train_time,test_time=avg_test_time,std=pr_std)\n",
    "        \n",
    "        #Precision\n",
    "        PrintDetails(metric=met,measure=\"Micro Precision\",Arr=mprecision_avg,kList=list1,train_time=avg_train_time,test_time=avg_test_time,std=mpr_std)\n",
    "\n",
    "\n",
    "        #Recall\n",
    "        PrintDetails(metric=met,measure=\"Recall\",Arr=recall_avg,kList=list1,train_time=avg_train_time,test_time=avg_test_time,std=rcl_std)\n",
    "        \n",
    "         #Recall\n",
    "        PrintDetails(metric=met,measure=\"Micro Recall\",Arr=mrecall_avg,kList=list1,train_time=avg_train_time,test_time=avg_test_time,std=mrcl_std)\n",
    "\n",
    "\n",
    "        #f measure\n",
    "        PrintDetails(metric=met,measure=\"F Measure\",Arr=macroFMeasure_avg,kList=list1,train_time=avg_train_time,test_time=avg_test_time,std=F_std)\n",
    "        \n",
    "       \n",
    "       \n",
    "        #f measure\n",
    "        PrintDetails(metric=met,measure=\"Micro F Measure\",Arr=mFMeasure_avg,kList=list1,train_time=avg_train_time,test_time=avg_test_time,std=mF_std)\n",
    "\n",
    "\n",
    "        #roc\n",
    "        PrintDetails(metric=met,measure=\"ROC\",Arr=roc_avg,kList=list1,train_time=avg_train_time,test_time=avg_test_time,std=roc_std)\n",
    "\n",
    "        #average Mean precision\n",
    "        PrintDetails(metric=met,measure=\"AMP\",Arr=AMP_avg,kList=list1,train_time=avg_train_time,test_time=avg_test_time,std=amp_std)\n",
    "         \n",
    "        #MAE\n",
    "        PrintDetails(metric=met,measure=\"MAE\",Arr=mae_avg,kList=list1,train_time=avg_train_time,test_time=avg_test_time,std=mae_std)\n",
    "        \n",
    "        tables.close()\n",
    "        print(\"###############\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
